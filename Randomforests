import os
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt


# After having the extracted_features.csv

def load_and_merge_data(feature_file, age_file):
    """
    Load features and age CSVs, merge on Patient_ID, and return a DataFrame.
    """
    try:
        features_df = pd.read_csv(feature_file)
        if 'ID' not in features_df.columns:
            raise ValueError("ID column not found in extracted_features.csv")
        
        age_df = pd.read_csv(age_file)
        if 'ID' not in age_df.columns or 'Age' not in age_df.columns:
            raise ValueError("ID or Age column not found in oasis_cross-sectional-5708aa0a98d82080.csv")
        
        df = pd.merge(features_df, age_df[['ID', 'Age']], on='ID', how='inner')
        
        if df.empty:
            raise ValueError("No matching Patient_IDs found between feature and age CSVs")
        
        print(f"Merged data for {len(df)} patients.")
        return df
    except Exception as e:
        print(f"Error loading or merging data: {e}")
        return None




def perform_rf_regression(df):
    """
    Perform Random Forest regression with enhanced training and calculate brain age gap.
    Returns model, predictions, feature importances, and brain age gap.
    """
    X = df.drop(columns=['ID', 'Age'])
    y = df['Age']
    feature_names = X.columns
    
    # Normalize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
    
    # Define Random Forest model and expanded hyperparameter grid
    rf = RandomForestRegressor(random_state=42)
    param_grid = {
        'n_estimators': [100, 200, 500, 1000],
        'max_depth': [None, 10, 20, 30, 50],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['auto', 'sqrt', 0.5]
    }
    
    # Perform grid search with increased cross-validation folds
    grid_search = GridSearchCV(rf, param_grid, cv=10, scoring='neg_mean_absolute_error', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    
    # Best model
    model = grid_search.best_estimator_
    print(f"Best Random Forest parameters: {grid_search.best_params_}")
    
    # Cross-validated performance of best model
    mae_scores = -cross_val_score(model, X_scaled, y, cv=10, scoring='neg_mean_absolute_error')
    print(f"Cross-validated MAE: {mae_scores.mean():.2f} ± {mae_scores.std():.2f} years")
    
    # Predict brain age
    y_pred = model.predict(X_test)
    
    # Calculate brain age gap
    brain_age_gap = y_pred - y_test
    
    # Evaluate on test set
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    print(f"Test Set Mean Absolute Error: {mae:.2f} years")
    print(f"Test Set R² Score: {r2:.2f}")
    
    # Feature importance
    importances = model.feature_importances_
    feature_importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': importances
    }).sort_values(by='Importance', ascending=False)
    print("\nFeature Importance:")
    print(feature_importance_df)
    
    return model, X_test, y_test, y_pred, brain_age_gap, df.loc[y_test.index, 'ID'], feature_importance_df




def visualize_results(y_test, y_pred, brain_age_gap, feature_importance_df):
    """
    Visualize predicted vs actual age, brain age gap distribution, and feature importance.
    """
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.scatter(y_test, y_pred, alpha=0.5)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('Actual Age')
    plt.ylabel('Predicted Age')
    plt.title('Predicted vs Actual Brain Age (Random Forest)')
    
    plt.subplot(1, 3, 2)
    plt.hist(brain_age_gap, bins=20, edgecolor='black')
    plt.xlabel('Brain Age Gap (Predicted - Actual)')
    plt.ylabel('Frequency')
    plt.title('Brain Age Gap Distribution (Random Forest)')
    
    plt.subplot(1, 3, 3)
    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
    plt.xlabel('Importance')
    plt.title('Feature Importance')
    
    plt.tight_layout()
    plt.show()




if __name__ == "__main__":
    parent_dir = input("Users/wjw_4/Documents/Helsa")
    
    feature_file = os.path.join(parent_dir, 'extracted_features.csv')
    age_file = os.path.join(parent_dir, 'oasis_cross-sectional-5708aa0a98d82080.csv')
    
    print("Loading and merging data...")
    df = load_and_merge_data(feature_file, age_file)
    
    if df is None or df.empty:
        print("Failed to load data. Please check file paths and formats.")
    else:
        print("Data preview:")
        print(df.head())
        
        print("\nTraining Random Forest model...")
        model, X_test, y_test, y_pred, brain_age_gap, test_patient_ids, feature_importance_df = perform_rf_regression(df)
        
        print("\nVisualizing results...")
        visualize_results(y_test, y_pred, brain_age_gap, feature_importance_df)
        
        results = pd.DataFrame({
            'ID': test_patient_ids,
            'Actual_Age': y_test,
            'Predicted_Age': y_pred,
            'Brain_Age_Gap': brain_age_gap
        })
        results.to_csv(os.path.join(parent_dir, 'RE_rf_results.csv'), index=False)
        print(f"\nResults saved to {os.path.join(parent_dir, 'RE_rf_results.csv')}")
